{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZGkWjl_UeK2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "trainset = \"processed/train.h5\"\n",
        "valset = \"processed/test.h5\"\n",
        "testset= \"processed/test.h5\"\n",
        "#!wget https://repository.library.northeastern.edu/downloads/neu:4f24c004s?datastream_id=content\n",
        "#!cp drive/MyDrive/colab/signal_bank.zip .\n",
        "#!unzip signal_bank.zip\n",
        "#!cp processed/* drive/MyDrive/colab/\n",
        "#!mkdir processed\n",
        "#!cp drive/MyDrive/colab/*.h5 processed/"
      ],
      "metadata": {
        "id": "YQVKqSylR_yI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypeVarTuple\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "###################################\n",
        "### PROJECT SPECIFIC PARAMETERS ###\n",
        "###################################\n",
        "\n",
        "#if enabled will plot a sample\n",
        "debug = False\n",
        "#total number of training/testing samples to generate\n",
        "nsamples = 50_000\n",
        "#max number of signals to be plotted at the same time in frequency\n",
        "max_simultaneous_signals = 2\n",
        "#total observable bandwidth (for our signal bank this needs to be a multiple of 25MHz)\n",
        "bw = 25_000_000\n",
        "#input size to the NN (for our signal bank this needs to be a multiple of 1024)\n",
        "buf = 1024\n",
        "#frequency resolution or bw of a single bin in the NN input\n",
        "resolution = (bw/1000000)/buf\n",
        "#probabliity that the entire observable bandwith doesnt contain any signal\n",
        "prob_empty = 0.05\n",
        "#probability that the first signal injected into the input is centered\n",
        "prob_centered = 0.5\n",
        "\n",
        "nclasses = 5\n",
        "\n",
        "#dict containing indexes of rows belonging to each protocol in classification label matrix\n",
        "#(note \"empty\" doesnt get its own row in the matrix) you can think of these as class labels\n",
        "#where each value corresponds to the row that will contain 1 in columns/IQs where that signal is present\n",
        "#and 0 where it isnt\n",
        "label_dict_str= {\n",
        "    'wifi'      : 0,\n",
        "    'lte'       : 1,\n",
        "    'zigbee'    : 2,\n",
        "    'lora'      : 3,\n",
        "    'ble'       : 4\n",
        "}\n",
        "\n",
        "#flipped version of above dict\n",
        "label_dict_int = dict([(value, key) for key, value in label_dict_str.items()])\n",
        "\n",
        "#dict of bw for each signal in mhz\n",
        "signal_bw_mhz_dict = {\n",
        "    'wifi'      : 20,\n",
        "    'lte'       : 10,\n",
        "    'zigbee'    : 2,\n",
        "    'lora'      : 0.5,\n",
        "    'ble'       : 1\n",
        "}\n",
        "\n",
        "#dict of bw for each signal in number of IQs\n",
        "signal_bw_mhz_niqs = {}\n",
        "for label in signal_bw_mhz_dict:\n",
        "    niqs = np.ceil(signal_bw_mhz_dict[label]/resolution)\n",
        "\n",
        "    if niqs%2 == 1:\n",
        "        niqs += 1\n",
        "\n",
        "    signal_bw_mhz_niqs[label] = int(niqs)\n",
        "\n",
        "#path to signal bank dir\n",
        "#each class should have its own h5 file i.e. lora.h5, wifi.h5 etc\n",
        "data_fp = './signal_bank/'\n",
        "final_folder_fp = './processed/'\n",
        "if not os.path.isdir(final_folder_fp):\n",
        "    os.mkdir(final_folder_fp)\n",
        "\n",
        "###################################\n",
        "### PROJECT SPECIFIC PARAMETERS ###\n",
        "###################################\n",
        "\n",
        "\n",
        "#grab random signal from signal bank\n",
        "def get_sample(protocol):\n",
        "    f_signal = h5py.File(data_fp + protocol + '.h5', 'r')\n",
        "    samp = f_signal[protocol][np.random.randint(f_signal[protocol].shape[0])]\n",
        "    f_signal.close()\n",
        "    return samp\n",
        "\n",
        "\n",
        "if __name__ == '__main__1':\n",
        "\n",
        "    all_labels = []\n",
        "    all_inputs = []\n",
        "\n",
        "    #if you want to omit a class you can remove them from below list\n",
        "    protocols_used = [0,1,2,3,4]\n",
        "    for i in tqdm(range(nsamples)):\n",
        "        label = np.zeros([nclasses,buf], dtype=int)\n",
        "        input_samp = np.zeros([buf, 2])\n",
        "\n",
        "        if np.random.rand() > prob_empty:\n",
        "            nsignals = np.random.randint(1,max_simultaneous_signals+1)\n",
        "\n",
        "            signal_protocols = np.zeros(nsignals)\n",
        "            signal_freqs = np.zeros(nsignals)\n",
        "            prev_centered = False\n",
        "\n",
        "            for j in range(nsignals):\n",
        "                protocol = np.random.choice(protocols_used)\n",
        "                signal_protocols[j] = protocol\n",
        "\n",
        "                signal_bw = signal_bw_mhz_niqs[label_dict_int[protocol]]\n",
        "                temp_input = np.zeros([buf+signal_bw*2-2,2])\n",
        "\n",
        "                samp = get_sample(label_dict_int[protocol])\n",
        "                samp_cut = samp[buf//2-signal_bw//2:buf//2+signal_bw//2,:]\n",
        "\n",
        "                if np.random.rand() < prob_centered and not prev_centered:\n",
        "                    signal_location = int(len(temp_input)/2-signal_bw/2)\n",
        "                    prev_centered = True\n",
        "                else:\n",
        "                    signal_location = int(np.random.choice(len(temp_input)-signal_bw+1))\n",
        "\n",
        "\n",
        "\n",
        "                temp_mask = np.zeros(buf+signal_bw*2-2, dtype=bool)\n",
        "                temp_mask[signal_location:signal_location + signal_bw] = True\n",
        "\n",
        "                signal_freqs[j] = signal_location*resolution\n",
        "\n",
        "                temp_input[signal_location:signal_location+signal_bw,:] += samp_cut\n",
        "                label[protocol] |= temp_mask[signal_bw-1:signal_bw+buf-1]\n",
        "                input_samp += temp_input[signal_bw-1:signal_bw+buf-1,:]\n",
        "\n",
        "\n",
        "        input_samp += get_sample('empty')\n",
        "        all_inputs.append(input_samp)\n",
        "        all_labels.append(label)\n",
        "\n",
        "\n",
        "        if debug:\n",
        "            plt.plot(np.linspace(-bw/1_000_000/2,bw/1_000_000/2,buf),abs(input_samp[:,0] + 1j*input_samp[:,1]))\n",
        "            plt.xlabel('MHz')\n",
        "            plt.title(signal_protocols)\n",
        "            plt.show()\n",
        "\n",
        "    all_inputs = np.array(all_inputs)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        all_inputs, all_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "    f_test = h5py.File(\n",
        "        final_folder_fp + 'test.h5', 'w')\n",
        "    xtest = f_test.create_dataset('X', (X_test.shape[0], X_test.shape[1], X_test.shape[2]), dtype='f')\n",
        "    ytest = f_test.create_dataset('y', (y_test.shape[0],y_test.shape[1], y_test.shape[2]), dtype='i')\n",
        "\n",
        "    xtest[()] = X_test\n",
        "    ytest[()] = y_test\n",
        "\n",
        "    f_train = h5py.File(\n",
        "        final_folder_fp + 'train.h5', 'w')\n",
        "    xtrain = f_train.create_dataset('X', (X_train.shape[0], X_train.shape[1], X_train.shape[2]), dtype='f')\n",
        "    ytrain = f_train.create_dataset('y', (y_train.shape[0],y_train.shape[1], y_train.shape[2]), dtype='i')\n",
        "\n",
        "    xtrain[()] = X_train\n",
        "    ytrain[()] = y_train\n",
        "\n",
        "    f_test.close()\n",
        "    f_train.close()"
      ],
      "metadata": {
        "id": "BBVqmyDifRbm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h_heaOiKNrp_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel) -> None:\n",
        "        super(conv_block,self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channel,out_channel,3,1,1),\n",
        "            nn.BatchNorm1d(out_channel),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(out_channel,out_channel,3,1,1),\n",
        "            nn.BatchNorm1d(out_channel),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self,input):\n",
        "        return self.conv(input)\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self,in_channel,out_channel) -> None:\n",
        "        super(up_conv,self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv1d(in_channel,out_channel,3,1,1),\n",
        "            nn.BatchNorm1d(out_channel),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self,input):\n",
        "        return self.conv(input)\n",
        "\n",
        "class NonLocal1D(nn.Module):\n",
        "    def __init__(self, in_channels) -> None:\n",
        "        super(NonLocal1D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.inter_channels = in_channels//2 # bottleneck design (see section 3.3)\n",
        "\n",
        "        self.theta = nn.Conv1d(self.in_channels, self.inter_channels, 1)\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Conv1d(self.in_channels, self.inter_channels, 1),\n",
        "            nn.MaxPool1d(2), # maxpool to reduce computation to 1/4 (see section 3.3)\n",
        "        )\n",
        "        self.g = nn.Sequential(\n",
        "            nn.Conv1d(self.in_channels, self.inter_channels, 1),\n",
        "            nn.MaxPool1d(2),\n",
        "        )\n",
        "\n",
        "        self.wz = nn.Sequential(\n",
        "            nn.Conv1d(self.inter_channels, self.in_channels, 1),\n",
        "            nn.BatchNorm1d(self.in_channels),\n",
        "        )\n",
        "        nn.init.constant_(self.wz[1].weight, 0) # zero initialization (see section 3.3)\n",
        "        nn.init.constant_(self.wz[1].bias, 0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        g = self.g(input).view(input.size(0),self.inter_channels,-1)\n",
        "        g = g.permute(0,2,1)\n",
        "\n",
        "        theta = self.theta(input).view(input.size(0),self.inter_channels,-1)\n",
        "        theta = theta.permute(0,2,1)\n",
        "\n",
        "        phi = self.phi(input).view(input.size(0),self.inter_channels,-1)\n",
        "\n",
        "        f = torch.matmul(theta,phi)\n",
        "        f = nn.functional.softmax(f,dim=-1)\n",
        "\n",
        "        y = torch.matmul(f,g)\n",
        "        y = y.permute(0,2,1).contiguous()\n",
        "        y = y.view(input.size(0),self.inter_channels,*input.size()[2:])\n",
        "\n",
        "        wz = self.wz(y)\n",
        "\n",
        "        return wz+input\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "    def __init__(self,inchannel,outchannel,is_attention=False,alpha=1,beta=5) -> None:\n",
        "        super(U_Net,self).__init__()\n",
        "        self.is_attention = is_attention\n",
        "        self.beta = beta\n",
        "        self.pool = nn.MaxPool1d(2,2)\n",
        "        self.conv1 = conv_block(inchannel,int(64*alpha))\n",
        "        if self.beta > 1:\n",
        "            self.conv2 = conv_block(int(64*alpha),int(128*alpha))\n",
        "            if self.beta > 2:\n",
        "                self.conv3 = conv_block(int(128*alpha),int(256*alpha))\n",
        "                if self.beta > 3:\n",
        "                    self.conv4 = conv_block(int(256*alpha),int(512*alpha))\n",
        "                    if self.beta > 4:\n",
        "                        self.conv5 = conv_block(int(512*alpha),int(1024*alpha))\n",
        "\n",
        "                        self.upconv5 = up_conv(int(1024*alpha),int(512*alpha))\n",
        "                        self.decode5 = conv_block(int(1024*alpha),int(512*alpha))\n",
        "\n",
        "                    self.upconv4 = up_conv(int(512*alpha),int(256*alpha))\n",
        "                    self.decode4 = conv_block(int(512*alpha),int(256*alpha))\n",
        "\n",
        "                self.upconv3 = up_conv(int(256*alpha),int(128*alpha))\n",
        "                self.decode3 = conv_block(int(256*alpha),int(128*alpha))\n",
        "\n",
        "            self.upconv2 = up_conv(int(128*alpha),int(64*alpha))\n",
        "            self.decode2 = conv_block(int(128*alpha),int(64*alpha))\n",
        "\n",
        "        self.decode1 = nn.Conv1d(int(64*alpha),outchannel,1,1)\n",
        "        if self.is_attention:\n",
        "            self.nonlocal1 = NonLocal1D(outchannel)\n",
        "\n",
        "    def forward(self,input):\n",
        "        # encoder path\n",
        "        e1 = self.conv1(input)\n",
        "        if self.beta > 1:\n",
        "            e2 = self.pool(e1)\n",
        "            e2 = self.conv2(e2)\n",
        "            if self.beta > 2:\n",
        "                e3 = self.pool(e2)\n",
        "                e3 = self.conv3(e3)\n",
        "                if self.beta > 3:\n",
        "                    e4 = self.pool(e3)\n",
        "                    e4 = self.conv4(e4)\n",
        "                    if self.beta > 4:\n",
        "                        e5 = self.pool(e4)\n",
        "                        e5 = self.conv5(e5)\n",
        "\n",
        "                        d5 = self.upconv5(e5)\n",
        "                        d5 = self.decode5(torch.cat((e4,d5),dim=1)) # channel first\n",
        "\n",
        "                        d4 = self.upconv4(d5)\n",
        "                        d4 = self.decode4(torch.cat((e3,d4),dim=1))\n",
        "                    else:\n",
        "                        d4 = self.upconv4(e4)\n",
        "                        d4 = self.decode4(torch.cat((e3,d4),dim=1))\n",
        "\n",
        "                    d3 = self.upconv3(d4)\n",
        "                    d3 = self.decode3(torch.cat((e2,d3),dim=1))\n",
        "                else:\n",
        "                    d3 = self.upconv3(e3)\n",
        "                    d3 = self.decode3(torch.cat((e2,d3),dim=1))\n",
        "\n",
        "                d2 = self.upconv2(d3)\n",
        "                d2 = self.decode2(torch.cat((e1,d2),dim=1))\n",
        "            else:\n",
        "                d2 = self.upconv2(e2)\n",
        "                d2 = self.decode2(torch.cat((e1,d2),dim=1))\n",
        "\n",
        "            d1 = self.decode1(d2)\n",
        "        else:\n",
        "            d1 = self.decode1(e1)\n",
        "\n",
        "        if self.is_attention:\n",
        "            d1 = self.nonlocal1(d1)\n",
        "\n",
        "        return torch.sigmoid(d1)\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryFocalLoss(nn.Module):\n",
        "    def __init__(self,alpha=None,gamma=2, reduction=True) -> None:\n",
        "        super(BinaryFocalLoss,self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.bce = nn.BCELoss(reduction=\"none\")\n",
        "        self.reduction = reduction\n",
        "    def forward(self,y_pred,y_true):\n",
        "        if self.alpha is not None:\n",
        "            alpha = torch.where(y_true == 1.0, self.alpha, (1.0 - self.alpha))\n",
        "        else:\n",
        "            alpha = 1\n",
        "\n",
        "        # Ensure that y_pred and y_true have the same shape before applying torch.where\n",
        "        if y_pred.shape != y_true.shape:\n",
        "            print(\"Warning: Shape mismatch between y_pred and y_true.\")\n",
        "            print(\"y_pred shape:\", y_pred.shape)\n",
        "            print(\"y_true shape:\", y_true.shape)\n",
        "            # Handle the shape mismatch (e.g., by resizing or broadcasting)\n",
        "            # For example, if y_pred has an extra dimension:\n",
        "            y_pred = y_pred.squeeze(1)  # Remove the extra dimension\n",
        "\n",
        "\n",
        "        pt = torch.where(y_true == 1.0, y_pred, 1 - y_pred)\n",
        "        bce = self.bce(y_pred,y_true)\n",
        "        loss = alpha*torch.pow(1.0 - pt, self.gamma)*bce\n",
        "        if self.reduction:\n",
        "            return torch.mean(loss)\n",
        "        return torch.mean(loss,dim=(1,2))"
      ],
      "metadata": {
        "id": "Ir3mAD6HRrFd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import h5py\n",
        "\n",
        "class MultilabelDataset(Dataset):\n",
        "    def __init__(self,h5file,norm=True) -> None:\n",
        "        df = h5py.File(h5file)\n",
        "        self.data = df['X']\n",
        "        self.label = df['y']\n",
        "        self.norm = norm\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        X = torch.from_numpy(self.data[idx].T)\n",
        "        y = torch.from_numpy(self.label[idx][1:])\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "hQHW-ANVRk3o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import cpu_count\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TrainValHandler():\n",
        "    def __init__(self,model,device,trainset,valset,save_path,\n",
        "                 alpha=None,gamma=0,ohem=False,\n",
        "                 lr=1e-3,epochs=90,patience=50,batchsize=1024,nbatches=2) -> None:\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.path = save_path\n",
        "        self.trainset = MultilabelDataset(trainset)\n",
        "        self.valset = MultilabelDataset(valset)\n",
        "\n",
        "        self.loss = BinaryFocalLoss(alpha,gamma,reduction=not ohem)\n",
        "        self.optim = torch.optim.Adam(self.model.parameters(),lr=lr)\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optim,step_size=30,gamma=0.1)\n",
        "        self.epochs = epochs\n",
        "        self.patience = patience\n",
        "        self.min_loss = torch.inf\n",
        "        self.ohem = ohem\n",
        "        self.batchsize = batchsize\n",
        "        self.nbatches = nbatches\n",
        "\n",
        "        try:\n",
        "            workers = cpu_count()\n",
        "        except:\n",
        "            workers = 1\n",
        "        if ohem:\n",
        "            self.traindataloader = DataLoader(self.trainset,self.batchsize*self.nbatches,shuffle=True,num_workers=workers)\n",
        "        else:\n",
        "            self.traindataloader = DataLoader(self.trainset,self.batchsize,shuffle=True,num_workers=workers)\n",
        "        self.valdataloader = DataLoader(self.valset,self.batchsize,shuffle=True,num_workers=workers)\n",
        "\n",
        "    def save_model(self):\n",
        "        path = self.path\n",
        "        torch.save(self.model.state_dict(),path)\n",
        "\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        train_loss = 0\n",
        "        for i, samples in enumerate(self.traindataloader):\n",
        "            x,y = samples\n",
        "            x = x.to(self.device,dtype=torch.float)\n",
        "            y = y.to(self.device,dtype=torch.float)\n",
        "            pred = self.model(x)\n",
        "            if self.ohem:\n",
        "                loss,_ = torch.topk(self.loss(pred,y),pred.shape[0]//self.nbatches)\n",
        "                loss = torch.mean(loss)\n",
        "            else:\n",
        "                loss = self.loss(pred,y)\n",
        "            self.optim.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optim.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            print('batch %d/%d, training loss %.6f' % (i+1,len(self.traindataloader),train_loss/(i+1)),end='\\r')\n",
        "        return train_loss/len(self.traindataloader)\n",
        "\n",
        "    def val_one_epoch(self):\n",
        "        self.model.eval()\n",
        "        val_loss = 0\n",
        "        for i, samples in enumerate(self.valdataloader):\n",
        "            x,y = samples\n",
        "            x = x.to(self.device,dtype=torch.float)\n",
        "            y = y.to(self.device,dtype=torch.float)\n",
        "            with torch.no_grad():\n",
        "                pred = self.model(x)\n",
        "                loss = self.loss(pred,y)\n",
        "                if self.ohem:\n",
        "                    loss = torch.mean(loss)\n",
        "                val_loss += loss.item()\n",
        "        return val_loss/len(self.valdataloader)\n",
        "\n",
        "    def train(self):\n",
        "        self.model.to(self.device)\n",
        "        patience = 0\n",
        "        history = {\n",
        "            \"training loss\":[],\n",
        "            \"validation loss\":[]\n",
        "        }\n",
        "        for epoch in range(self.epochs):\n",
        "            train_loss = self.train_one_epoch()\n",
        "            val_loss = self.val_one_epoch()\n",
        "            self.scheduler.step()\n",
        "            history[\"training loss\"].append(train_loss)\n",
        "            history[\"validation loss\"].append(val_loss)\n",
        "            print(\"epoch %d/%d, training loss: %.6f, validation loss: %.6f\"%(epoch+1,self.epochs,train_loss,val_loss))\n",
        "            if val_loss < self.min_loss:\n",
        "                self.min_loss = val_loss\n",
        "                patience = 0\n",
        "                self.save_model()\n",
        "                print(\"save best model at epch %d\"%(epoch+1))\n",
        "            else:\n",
        "                patience += 1\n",
        "\n",
        "            if patience == self.patience:\n",
        "                print(\"no improvement from last %d epoch, stop training\"%patience)\n",
        "                break\n",
        "        return history\n",
        "\n",
        "class TestHandler():\n",
        "    def __init__(self,model,device,testset,batchsize,\n",
        "                 labels = [\"WiFi\", \"LTE\", \"Zigbee\", \"LoRa\", \"BLE\"]) -> None:\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "        self.testset = MultilabelDataset(testset)\n",
        "        try:\n",
        "            workers = cpu_count()\n",
        "        except:\n",
        "            workers = 1\n",
        "        self.testdataloader = DataLoader(self.testset,batchsize,shuffle=True,num_workers=workers)\n",
        "        self.labels = labels\n",
        "\n",
        "    def eval_one_step(self,i):\n",
        "        x,y = self.testset[i]\n",
        "        x = x.reshape((1,)+x.shape)\n",
        "        y = y.reshape((1,)+y.shape)\n",
        "        x = x.to(self.device,dtype=torch.float)\n",
        "        y = y.to(self.device,dtype=torch.float)\n",
        "        with torch.no_grad():\n",
        "            y_pred = self.model(x)\n",
        "\n",
        "        y_pred[y_pred>=0.5] = 1\n",
        "        y_pred[y_pred<0.5] = 0\n",
        "\n",
        "        return y, y_pred\n",
        "\n",
        "    def get_plot(self,y,plotname):\n",
        "        if self.device != \"cpu\":\n",
        "            data = y.cpu()\n",
        "        fig,axes = plt.subplots(data.shape[1],sharex=True,figsize=(8,6))\n",
        "        for i, ax in enumerate(axes):\n",
        "            ax.imshow(data[:,i,:].reshape(1,-1),cmap='cividis',aspect='auto',extent=[-12.5,12.5,1,0])\n",
        "            ax.set_ylabel(self.labels[i],fontsize=12)\n",
        "            ax.set_yticks([])\n",
        "\n",
        "        fig.supxlabel(\"Frequency (MHz)\",fontsize=18)\n",
        "        fig.savefig(plotname,format='eps')\n",
        "\n",
        "    def display(self,i):\n",
        "        y, y_pred = self.eval_one_step(i)\n",
        "        self.get_plot(y_pred,\"predicted%d\"%i)\n",
        "        self.get_plot(y,\"groundtruth%d\"%i)\n",
        "\n",
        "    def compute_iou(self,intersec,union):\n",
        "        iou = intersec/union\n",
        "        return torch.nan_to_num(iou)\n",
        "\n",
        "    def compute_recall(self,intersec,area_t):\n",
        "        recall = intersec/area_t\n",
        "        return torch.nan_to_num(recall)\n",
        "\n",
        "    def compute_precision(self,intersec,area_p):\n",
        "        precision = intersec/area_p\n",
        "        return torch.nan_to_num(precision)\n",
        "\n",
        "    def evaluate(self):\n",
        "        intersec = []\n",
        "        union = []\n",
        "        area_t = []\n",
        "        area_p = []\n",
        "        for i, samples in enumerate(self.testdataloader):\n",
        "            x,y = samples\n",
        "            x = x.to(self.device,dtype=torch.float)\n",
        "            y = y.to(self.device,dtype=torch.float)\n",
        "            with torch.no_grad():\n",
        "                y_pred = self.model(x)\n",
        "            y_pred[y_pred>=0.5] = 1\n",
        "            y_pred[y_pred<0.5] = 0\n",
        "\n",
        "            intersec_batch = torch.sum(torch.logical_and(y,y_pred),(0,2))\n",
        "            union_batch = torch.sum(torch.logical_or(y,y_pred),(0,2))\n",
        "            area_true_batch = torch.sum(y,(0,2))\n",
        "            area_pred_batch = torch.sum(y_pred,(0,2))\n",
        "\n",
        "            intersec.append(intersec_batch)\n",
        "            union.append(union_batch)\n",
        "            area_t.append(area_true_batch)\n",
        "            area_p.append(area_pred_batch)\n",
        "\n",
        "            mean_iou = torch.mean(self.compute_iou(intersec_batch,union_batch))\n",
        "            print(\"batch %d/%d, mean iou: %.6f\"%(i+1,len(self.testdataloader),mean_iou),end='\\r')\n",
        "        intersec = torch.sum(torch.stack(intersec,0),dim=0)\n",
        "        union = torch.sum(torch.stack(union,0),dim=0)\n",
        "        area_t = torch.sum(torch.stack(area_t,0),dim=0)\n",
        "        area_p = torch.sum(torch.stack(area_p,0),dim=0)\n",
        "        iou = self.compute_iou(intersec,union)\n",
        "        recall = self.compute_recall(intersec,area_t)\n",
        "        precision = self.compute_precision(intersec,area_p)\n",
        "        return iou.cpu().numpy(), recall.cpu().numpy(), precision.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "a5GOzKI9RbyM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model = U_Net(2,4,is_attention=True,alpha=1,beta=5)\n",
        "    batchsize = 256\n",
        "    lr=1e-3\n",
        "    epochs=100\n",
        "    pt=30\n",
        "    ckpt = 'multilabel.pth'\n",
        "    handler = TrainValHandler(model,device,trainset,valset,ckpt,lr=lr,epochs=epochs,patience=pt,batchsize=batchsize)\n",
        "    history = handler.train()\n",
        "\n",
        "    # retrieve the best model and convert to onnx\n",
        "    # model.load_state_dict(torch.load(ckpt), strict=False)\n",
        "    # model.eval()\n",
        "    # dummy_input = torch.randn(1, 2, 1024, requires_grad=True)\n",
        "    # torch_out = model(dummy_input)\n",
        "    # torch.onnx.export(model,         # model being run\n",
        "    #         dummy_input,       # model input (or a tuple for multiple inputs)\n",
        "    #         \"multilabel.onnx\",       # where to save the model\n",
        "    #         export_params=True,  # store the trained parameter weights inside the model file\n",
        "    #         opset_version=11,    # the ONNX version to export the model to\n",
        "    #         do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "    #         input_names = ['modelInput'],   # the model's input names\n",
        "    #         output_names = ['modelOutput'], # the model's output names\n",
        "    #         dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes\n",
        "    #                             'modelOutput' : {0 : 'batch_size'}})\n",
        "    # print(\" \")\n",
        "    # print('Model has been converted to ONNX')\n",
        "\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h7pblghlOo5T",
        "outputId": "84790053-9f75-4cc2-f84e-ad5f79116d25"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 175/176, training loss 0.172076\rbatch 176/176, training loss 0.171447\repoch 1/100, training loss: 0.171447, validation loss: 0.076472\n",
            "save best model at epch 1\n",
            "epoch 2/100, training loss: 0.050262, validation loss: 0.070152\n",
            "save best model at epch 2\n",
            "epoch 3/100, training loss: 0.031667, validation loss: 0.028806\n",
            "save best model at epch 3\n",
            "epoch 4/100, training loss: 0.023301, validation loss: 0.058736\n",
            "epoch 5/100, training loss: 0.020155, validation loss: 0.075526\n",
            "epoch 6/100, training loss: 0.017992, validation loss: 0.021810\n",
            "save best model at epch 6\n",
            "epoch 7/100, training loss: 0.016255, validation loss: 0.030605\n",
            "epoch 8/100, training loss: 0.015410, validation loss: 0.022060\n",
            "epoch 9/100, training loss: 0.014329, validation loss: 0.021407\n",
            "save best model at epch 9\n",
            "epoch 10/100, training loss: 0.013604, validation loss: 0.046376\n",
            "epoch 11/100, training loss: 0.012819, validation loss: 0.023098\n",
            "epoch 12/100, training loss: 0.012381, validation loss: 0.048972\n",
            "epoch 13/100, training loss: 0.011974, validation loss: 0.016469\n",
            "save best model at epch 13\n",
            "epoch 14/100, training loss: 0.011848, validation loss: 0.021615\n",
            "epoch 15/100, training loss: 0.011616, validation loss: 0.059305\n",
            "epoch 16/100, training loss: 0.010729, validation loss: 0.018753\n",
            "epoch 17/100, training loss: 0.010678, validation loss: 0.014980\n",
            "save best model at epch 17\n",
            "epoch 18/100, training loss: 0.010666, validation loss: 0.014948\n",
            "save best model at epch 18\n",
            "epoch 19/100, training loss: 0.010003, validation loss: 0.013346\n",
            "save best model at epch 19\n",
            "epoch 20/100, training loss: 0.009715, validation loss: 0.018617\n",
            "epoch 21/100, training loss: 0.009436, validation loss: 0.012839\n",
            "save best model at epch 21\n",
            "epoch 22/100, training loss: 0.009221, validation loss: 0.016120\n",
            "epoch 23/100, training loss: 0.008859, validation loss: 0.019325\n",
            "epoch 24/100, training loss: 0.008764, validation loss: 0.029605\n",
            "epoch 25/100, training loss: 0.008249, validation loss: 0.017185\n",
            "epoch 26/100, training loss: 0.008055, validation loss: 0.026265\n",
            "epoch 27/100, training loss: 0.007812, validation loss: 0.033502\n",
            "epoch 28/100, training loss: 0.007435, validation loss: 0.016143\n",
            "epoch 29/100, training loss: 0.007483, validation loss: 0.014621\n",
            "epoch 30/100, training loss: 0.007121, validation loss: 0.017826\n",
            "epoch 31/100, training loss: 0.005358, validation loss: 0.010020\n",
            "save best model at epch 31\n",
            "epoch 32/100, training loss: 0.004641, validation loss: 0.010577\n",
            "epoch 33/100, training loss: 0.004414, validation loss: 0.010577\n",
            "epoch 34/100, training loss: 0.004282, validation loss: 0.010808\n",
            "epoch 35/100, training loss: 0.004019, validation loss: 0.010616\n",
            "epoch 36/100, training loss: 0.003901, validation loss: 0.010725\n",
            "epoch 37/100, training loss: 0.003757, validation loss: 0.011017\n",
            "epoch 38/100, training loss: 0.003592, validation loss: 0.011327\n",
            "epoch 39/100, training loss: 0.003456, validation loss: 0.011319\n",
            "epoch 40/100, training loss: 0.003372, validation loss: 0.011493\n",
            "epoch 41/100, training loss: 0.003255, validation loss: 0.012860\n",
            "epoch 42/100, training loss: 0.003129, validation loss: 0.011670\n",
            "epoch 43/100, training loss: 0.003117, validation loss: 0.012084\n",
            "epoch 44/100, training loss: 0.002949, validation loss: 0.011956\n",
            "epoch 45/100, training loss: 0.002863, validation loss: 0.012323\n",
            "epoch 46/100, training loss: 0.002753, validation loss: 0.012392\n",
            "epoch 47/100, training loss: 0.002699, validation loss: 0.013417\n",
            "epoch 48/100, training loss: 0.002667, validation loss: 0.012758\n",
            "epoch 49/100, training loss: 0.002499, validation loss: 0.013418\n",
            "epoch 50/100, training loss: 0.002404, validation loss: 0.012734\n",
            "epoch 51/100, training loss: 0.002395, validation loss: 0.014134\n",
            "epoch 52/100, training loss: 0.002315, validation loss: 0.012977\n",
            "epoch 53/100, training loss: 0.002257, validation loss: 0.013489\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ae6cc7d1ed46>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-ae6cc7d1ed46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'multilabel.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainValHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# retrieve the best model and convert to onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a44a03998596>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         }\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a44a03998596>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch %d/%d, training loss %.6f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraindataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraindataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model = U_Net(2,4,is_attention=True,alpha=1,beta=5)\n",
        "    batchsize = 256\n",
        "    ckpt = 'multilabel.pth'\n",
        "    model.load_state_dict(torch.load(ckpt), strict=False)\n",
        "    handler = TestHandler(model,device,testset,batchsize)\n",
        "    iou, recall, precision = handler.evaluate()\n",
        "    handler.display(2)\n",
        "    print('iou:',iou)\n",
        "    print('precision:',precision)\n",
        "    print('recall:',recall)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v2R4UQchSVPs",
        "outputId": "f9b524ff-6657-44bb-a5cd-4c905759865a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iou: [0.8921427  0.9784342  0.99328727 0.9256809 ]\n",
            "precision: [0.9671847  0.9925923  0.9987669  0.97904384]\n",
            "recall: [0.9199901  0.9856314  0.9945069  0.94439304]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}